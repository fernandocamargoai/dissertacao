%\section{Resultados e Discussões}
\section{Results and Discussion}
\label{cap:resultadosDiscussoes}

%Deseja-se avaliar os resultados obtidos por esses algoritmos de acordo com os dois objetivos utilizados: diminuir os custos de geração térmica e aumentar o volume final dos reservatórios das usinas. Para facilitar a visualização das frentes de pareto, o volume final foi convertido em porcentagem, indo de 0 a 100\%. Além disso, os valores do volume final receberam valores negativos, sendo apresentados de -100 até 0\%.

We want to evaluate the results of the algorithms according to the goals: to decrease the thermal generation costs and to increate the final volume of the reservoirs of the plants. To make it easier to visualize the pareto front in the figures, the final volume is given in percentage. Beyond that, it's presented in negative numbers, from -100\% to 0\%.

%Os valores obtidos pelos algoritmos utilizados serão comparados entre si através de conhecidas métricas de qualidade, além da apresentação dos gráficos de suas frentes de pareto junto à frente de referência. Deve-se notar que, por não possuirmos uma frente de pareto de referência ideal com o melhor resultado possível, foi criada uma a partir dos melhores resultados de todas execuções de todos os algoritmos.

These results will be compared through known quality indicators and graphics showing the obtained pareto fronts with the reference pareto front. It's worth noting that, since we don't have the real pareto front with the optimum solutions, a reference pareto front was created with the best results of all the executions of all the algorithms. 

%\subsection{Perí­odo 1951-1956}
\subsection{1951-1956}

%Tratando-se de um período de seca, espera-se maior dificuldade na otimização da operação das usinas nesse período. Portanto, é um período chave na comparação entre os algoritmos.

Being a dry period, we expect it to be harder for the plants' operation to be optimized. So, this is a key period in the comparison of the algorithms.

%A Tabela \ref{table:epPeriodo1} apresenta a mediana e o desvio do valor \textit{I}$^{1}_{\epsilon+}$ obtido em todas execuções de cada algoritmo para esse período. Esse indicador mostra o quão próxima a frente de pareto obtida está da frente de pareto de referência, sendo melhor o resultado quanto menor o valor. Nessa tabela também está indicado em cinza escuro e cinza claro o melhor e o segundo melhor resultado, respectivamente. Uma última observação importante é que os valores apresentados entre parênteses após o nome de cada algoritmo referem-se ao valor do índice de distribuição utilizado nas operações de cruzamento e mutação, como discutido na Seção \ref{sec:parametrosUtilizados}. As tabelas seguintes serão apresentadas de maneira semelhante.

The Table \ref{table:epPeriodo1} presents the mean and the standard deviation of the \textit{I}$^{1}_{\epsilon+}$ Indicator obtained in all the executions of each algorithm of this period. This indicator shows how close the pareto front is in relation to the reference pareto front, being that the smaller the value the best is the result. In this table, the best and the second best results are highlighted with dark and light gray, respectively. It's also important to note that the values presented between parenthesis after the name of each algorithm refers to the value of the distribution index used in the combination and mutation operators, as discussed in the Section \ref{sec:parametrosUtilizados}. The other tables follow the same pattern.

\begin{table}[!t]
\caption{Mean and Standard Deviation of Additive Epsilon Indicator (\textit{I}$^{1}_{\epsilon+}$) of the first period}
\label{table:epPeriodo1}
\centering
\begin{tabular}{ll}
    ~                             & Mean and Standard Deviation               \\ \hline
    OMOPSO                        & $  2.52e-01_{ 4.5e-02}$                   \\
    SMPSO (1.0)                   & $  3.31e-01_{ 4.6e-02}$                   \\
    SMPSO (10.0)                  & $  3.29e-01_{ 4.9e-02}$                   \\
    SMPSO (20.0)                  & $  3.43e-01_{ 4.4e-02}$                   \\
    NSGA-II (1.0)                 & \cellcolor{gray25}$  1.40e-01_{ 2.3e-02}$ \\
    NSGA-II (10.0)                & $  2.20e-01_{ 4.7e-02}$                   \\
    NSGA-II (20.0)                & $  2.15e-01_{ 4.7e-02}$                   \\
    SPEA2 (1.0)                   & $  1.72e-01_{ 3.1e-02}$                   \\
    SPEA2 (10.0)                  & $  2.10e-01_{ 3.0e-02}$                   \\
    SPEA2 (20.0)                  & $  2.08e-01_{ 3.1e-02}$                   \\
    MOCell (1.0)                  & \cellcolor{gray95}$  1.07e-01_{ 2.7e-02}$ \\
    MOCell (10.0)                 & $  2.24e-01_{ 5.0e-02}$                   \\
    MOCell (20.0)                 & $  2.60e-01_{ 4.3e-02}$                   \\
\end{tabular}
\end{table}

%A primeira análise que pode-se fazer ao observarmos a Tabela \ref{table:epPeriodo1} é que, de modo geral, valores menores para o índice de distribuição geraram melhores resultados. Essa afirmação é verdadeira para todos algoritmos, porém, tendo uma ressalva em relação ao algoritmo SMPSO, que obteve resultados muito próximos com os índices de valor $1.0$ e $10.0$. Nota-se que apesar de uma mediana com valor ligeiramente menor para o índice $10.0$, seu desvio padrão também é ligeiramente maior. Assim, indica-se baixa variação nos resultados do algoritmo SMPSO com relação à alteração do parâmetro de índice de distribuição de seu operador de mutação.

The first analysis to be done after observing the Table \ref{table:epPeriodo1} is that, in general, smaller values of the distribution index generated better results. This affirmation is true for all the algorithms, even though the results of the SMPSO were very close for the values of $1.0$ and $10.0$ of distribution index. So, we can state that, in this case, the SMPSO suffers little influence of the variation of the distribution index of its mutation operator.

%Por outro lado, a diferença nos resultados dos outros algoritmos é considerável. Observa-se grande diferença entre os resultados dos algoritmos com índice $1.0$ em relação aos outros valores e uma pequena diferença entre os valores $10.0$ e $20.0$. Por fim, conclui-se que, pelo menos em relação a esse período e esse indicador, o valor $1.0$ é o melhor valor encontrado para a operação desses algoritmos com esse problema específico. Lembrando que o valor desse parâmetro funciona de tal forma que quanto menor ele seja, mais distantes poderão ser as soluções criadas através de cruzamentos e mutações. Isso permite maior exploração em troca de uma convergência mais lenta.

On the other hand, the difference of the results of the other algorithms are substantial. It's noticiable the great difference between the results of the algorithms with distribution index of $1.0$ and the other values. The difference between $10.0$ and $20.0$ is smaller. Lastly, we can deduce that, at least for this period and this indicator, the value $1.0$ is the best one found for the operation of these algorithms with this problem.

%Além disso, podemos notar que o claro vencedor nesse período de acordo com esse indicador foi o algoritmo MOCell, seguido pelo NSGA-II. Vale lembra que o \textit{I}$^{1}_{\epsilon+}$ mede apenas a convergência desses algoritmos em relação a frente de pareto de referência. Ou seja, mede o quão próximo seus resultados ficaram dessa referência, sendo melhor um resultado menor.

%Com o SPEA2 como terceiro colocado, podemos notar que a família de algoritmos evolucionários parece ter se adaptado melhor a esse problema do que aqueles de enxame de enxames, visto que seus todos seus representantes obtiveram resultados melhores do que o OMOPSO e o SMPSO.

Beyond that, we can notice that the clear winner of this period according to the \textit{I}$^{1}_{\epsilon+}$ Indicator was the MOCell, followed by NSGA-II. Having the SPEA2 as the third best, we can claim that the evolutionary algorithms had a better adaptation for this problem than the particle swarm optimization algorithms, since all the evolutionary algorithms had better results than both OMOPSO and SMPSO.

%Voltando nossa atenção aos algoritmos de enxame de partículas, o OMOPSO obteve melhor convergência que seu sucessor, SMPSO. Talvez, isso se deva às restrições de velocidade impostos às partículas pelo SMPSO. Afinal, como pudemos notar, uma maior exploração do espaço de busca rendeu melhores resultados aos demais algoritmos.

Turning attention to the particle swarm optimization algorithms, OMOPSO obtained a better convergence that its successor: SMPSO. Maybe, it's because of the speed constriction of the particles of SMPSO. After all, we can notice that a greater exploration of the environment yielded good results to the other algorithms, as pointed by the variation of the distribution index.

%Apesar desses resultados, a convergência não é o único aspecto importante em uma frente de pareto. Devemos observar a diversidade das soluções apresentadas. Afinal, o grande propósito na solução de problemas multiobjetivos é gerar diversas opções aos operadores do sistema, para que esses possam decidir a solução a ser adotada. Para avaliar esse aspecto das soluções, disponibiliza-se a Tabela \ref{table:spreadPeriodo1}.

Despite these results, the convergence isn't the only important aspect of a pareto front. We should also observe the diversity of the obtained solutions. In the end, the great purpose of the multi objective optimization is to generate various options for the system's operators, so they can decide the solution to be adopted. To evaluate this aspect of the solutions, there's the Table \ref{table:spreadPeriodo1}.

\begin{table}[!t]
\caption{Mean and Standard Deviation of the SPREAD Indicator ($\Delta$) of the first period}
\label{table:spreadPeriodo1}
\centering
\begin{tabular}{ll}
    ~              & Mean and Standard Deviation               \\ \hline
    OMOPSO         & $  5.99e-01_{ 4.8e-02}$                   \\
    SMPSO (1.0)    & \cellcolor{gray95}$  5.75e-01_{ 7.0e-02}$ \\
    SMPSO (10.0)   & \cellcolor{gray25}$  5.80e-01_{ 9.6e-02}$ \\
    SMPSO (20.0)   & $  5.85e-01_{ 1.1e-01}$                   \\
    NSGA-II (1.0)  & $  6.50e-01_{ 4.3e-02}$                   \\
    NSGA-II (10.0) & $  7.08e-01_{ 7.4e-02}$                   \\
    NSGA-II (20.0) & $  7.18e-01_{ 6.9e-02}$                   \\
    SPEA2 (1.0)    & $  7.38e-01_{ 7.6e-02}$                   \\
    SPEA2 (10.0)   & $  7.62e-01_{ 5.5e-02}$                   \\
    SPEA2 (20.0)   & $  7.48e-01_{ 4.8e-02}$                   \\
    MOCell (1.0)   & $  6.26e-01_{ 1.0e-01}$                   \\
    MOCell (10.0)  & $  6.93e-01_{ 6.9e-02}$                   \\
    MOCell (20.0)  & $  6.64e-01_{ 1.0e-01}$                   \\
\end{tabular}
\end{table}

%Com os resultados do Indicador $\Delta$, notamos resultados opostos aos encontrados com o Indicador \textit{I}$^{1}_{\epsilon+}$. Isso mostra que apesar de pior convergência dos algoritmos de enxame de partículas, eles obtiveram melhor diversidade de soluções do que aqueles da família de algoritmos evolucionários. Nesse quesito, destaca-se o SMPSO, que obteve a melhor diversidade com todos os valores do índice de distribuição, ultrapassando seu antecessor, OMPSO. Já dentre os algoritmos evolucionários, novamente o MOCell se saiu melhor que os outros. Sendo novamente seguido pelo NSGA-II e por último o SPEA2.

With the values of $\Delta$ Indicator, it's noticeable that the results were the oposite of what was found with the \textit{I}$^{1}_{\epsilon+}$ Indicator. It shows that despite the worst convergence of the particle swarm algorithms, they obtained a better diversity of solutions than what the evolutionary algorithms achieved. At this matter, the SMPSO is highlighted for achieving a greater diversity with all of the distribution indexes, surpassing its predecessor: OMOPSO. Among the evolutionary algorithms, the MOCell turned out better than the others once again. Also, the NSGA-II was once more better than the SPEA2.

%Quanta à análise dos valores de índice de distribuição, em mais um indicador tivemos o mesmo resultado: o valor menor obteve melhores resultados. Isso indica que realmente uma exploração mais intensa do espaço de soluções é algo benéfico na solução desse problema específico.

Regarding the analysis of the distribution index values, the same result was obtained: the smallest value achieved the best results. It reinforces that a more intensive exploration of the search space of solutions is benefitial to solve this problem.

\begin{table}[!t]
\caption{Mean and Standard Deviation of the Hypervolume Indicator (HV) of the first period}
\label{table:hvPeriodo1}
\centering
\begin{tabular}{ll}
    \hline
    ~              & Mean and Standard Deviation               \\ \hline
    OMOPSO         & $  4.80e-01_{ 4.3e-02}$                   \\
    SMPSO (1.0)    & $  4.02e-01_{ 3.1e-02}$                   \\
    SMPSO (10.0)   & $  3.85e-01_{ 4.1e-02}$                   \\
    SMPSO (20.0)   & $  3.96e-01_{ 3.8e-02}$                   \\
    NSGA-II (1.0)  & \cellcolor{gray95}$  6.25e-01_{ 1.8e-02}$ \\
    NSGA-II (10.0) & $  5.91e-01_{ 3.1e-02}$                   \\
    NSGA-II (20.0) & $  5.95e-01_{ 2.7e-02}$                   \\
    SPEA2 (1.0)    & $  5.99e-01_{ 1.9e-02}$                   \\
    SPEA2 (10.0)   & $  6.01e-01_{ 2.5e-02}$                   \\
    SPEA2 (20.0)   & \cellcolor{gray25}$  6.02e-01_{ 2.2e-02}$ \\
    MOCell (1.0)   & $  5.97e-01_{ 2.6e-02}$                   \\
    MOCell (10.0)  & $  5.47e-01_{ 3.3e-02}$                   \\
    MOCell (20.0)  & $  5.04e-01_{ 3.9e-02}$                   \\
\end{tabular}
\end{table}

%Para continuar a análise desse período, a Tabela \ref{table:hvPeriodo1} mostra o resultados dos algoritmos para o Indicador de Hipervolume. Esse indicador tem a propriedade única que avaliar ao mesmo tempo a convergência, a diversidade a ainda a cardinalidade das soluções. Esse indicador mede o tamanho do espaço objetivo coberto pela aproximação da frente de pareto em relação à frente de pareto de referência. Isso é feito através de um ponto de referência adotado. Note ainda que, diferente dos indicadores anteriores, esse tem como melhor valor aqueles maiores.

To continue the analysis of this period, the Table \ref{table:hvPeriodo1} shows the results of the algorithms for the Hypervolume Indicator. This indicator has an unique property of evaluate at the same time the convergence, the diversity and also the cardinality of the solutions. It measures the size of the objective space covered by the pareto front in relation to the reference pareto front. It's done through a reference point adopted. It's worth noting that different from the previous indicators, the higher the better the value of this indicator.

%Ao observarmos os resultados desse indicador, notamos que novamente os algoritmos evolucionários obtiveram melhores resultados que os de enxame de partículas. Porém, esse indicador muda um pouco a ordem dos melhores algoritmos. Nesse caso, o NSGA-II obteve o melho resultado de todos, sendo seguido, dessa vez, pelo SPEA2 e por último o MOCell, que havia obtido os melhores resultados de acordo com as métricas anteriores. Porém, a diferença dos resultados desses três algoritmos é pequena de acordo com essa métrica.

Observing the results of this indicator, it's noticiable that one more time the evolutionary algorithms achieved better results than the particle swarm optimization algorithms. However, the order of the best algorithms has changed. In this case, the NSGA-II obtained the best result, followed by SPEA2 and MOCell, which had the best results according to the previous indicators. Nevertheless, the difference of the results is tiny for this three algorithms according to HV Indicator.

%Voltando nossa atenção aos algoritmos de enxame de Partículas, notamos que novamente o OMOPSO superou seu sucessor, SMPSO. Seu resultado foi razoavelmente melhor nessa métrica, assim como na \textit{I}$^{1}_{\epsilon+}$. Isso indica que, em relação a seu antecessor, o SMPSO conseguiu ser melhor apenas na distribuição das soluções.

Turning our attention to the particle swarm algorithms, once again the OMOPSO surpassed its successor: SMPSO. Its result was fairly better with this indicator, as it was with \textit{I}$^{1}_{\epsilon+}$. This indicates that, related to its predecessor, the SMPSO was better only in the diversity of the solutions.

%Para essa métrica, houve grande diferença ao analisarmos os valores de índice de distribuição. Não houve mais o padrão de que um menor índice rendesse melhores resultados. Esse comportamento variou de acordo com o algoritmo estudado. Sendo que enquanto o melhor valor para o NSGA-II foi de $1.0$, o melhor valor do SPEA2 foi justamente o oposto: $20.0$. Já no caso do MOCell, não só o valor de $1.0$ foi melhor, como os outros valores geraram resultados consideravelmente inferiores em relação à essa métrica.

For this metric, there's a great difference in the analysis of the distribution index values. There wasn't the same pattern of the smallest value generating the best results. This behavior varied according to the studied algorithm. While the best value for NSGA-II was $1.0$, the best value for SPEA2 was exactly the oposite: $20.0$. In the case of the MOCell, the $1.0$ not only was the best, but also the other values generated fairly worse results according to this indicator.

%Se compararmos os melhores resultados para cada algoritmo, o NSGA-II saiu vencedor com uma consideravel vantagem. Enquanto isso, SPEA2 e MOCell obtiveram resultados bem próximos. Já o OMOPSO e o SMPSO obtiveram resultados bem inferiores em relação aos algoritmos evolucionários.

Comparing the best results of each algorithm, the NSGA-II was the winner with a substantial advantage. While SPEA2 and MOCell achieved close results. The worst results were from OMOPSO and SMPSO, that achieved poor results compared to the evolutionary algorithms.

%Com o estudo dessas três métricas, podemos concluir que os algoritmos evolucionários obtêm melhor convergência da frente de pareto, enquanto os de enxame de partículas obtêm soluções mais distribuídas. Porém, o resultado geral é que os algoritmos evolucionários se mostraram mais eficientes.

With the study of these three metrics, we can conclude that the evolutionary algorithms obtained better convergence of the pareto front, while the particle swarm algorithms achieved the best diversity of solutions. However, the general result is that the evolutionary algorithms are more efficient to solve this problem.

%Além desses resultados gerais, podemos observar uma inconsistência entre os indicadores. Apesar de ser considerado melhor tanto pelo \textit{I}$^{1}_{\epsilon+}$ quanto pelo $\Delta$, que tratam separadamente convergência e distribuição, o MOCell caiu para a terceira melhor opção quando avaliado pelo Hipervolume, que trata ambos aspectos ao mesmo tempo. Esse tipo de correlação entre os indicadores é discutida com maior profundidade em \cite{liefooghe2016}.

Beyond these general results, we must it's worth to observe the inconsistency between the indicators. Even though it was considered the best by both \textit{I}$^{1}_{\epsilon+}$ and $\Delta$, which treats separatly the convergence and diversity, the MOCell was only the third best when evaluated by the Hypervolume, which treats both of this aspects together. This correlation between the indicators is further discussed in \cite{liefooghe2016}.

%Para finalizar a análise desse período, seguiremos agora para o gráfico que mostra a frente de pareto de referência e as frentes de pareto geradas pela execução de cada algoritmo. Esse gráfico apresenta uma execução de cada algoritmo, sendo essa a que rendeu a mediana do Indicador \textit{I}$^{1}_{\epsilon+}$. Além disso, para não poluir sua visualização, será considerado apenas o melhor valor do índice de distribuição para cada algoritmo.

To finish the analysis of this period, we'll take a look at the graphic that shows the reference pareto front and the generated pareto fronts by the execution of each algorithm. This graphic presents one execution of each algorithm, being this execution the one which had the mean of the Indicador \textit{I}$^{1}_{\epsilon+}$. Besides that, to make the visualization easier, only the best result of the distribution index of each algorithm is shown in the graphic.

%Avaliando Figura \ref{fig:paretoEP1}, observamos primeiramente a frente de pareto de referência. Pode-se notar sua grande extensão, indo desde valores próximos de 100\% de volume final até valores próximos de 50\%, apresentando sempre os melhores valores encontrados para o custo térmico. Sua grande distribuição de valores se deve à combinação de todos os melhores pontos de todas as execuções de todos os algoritmos, que juntos formaram essa Frente de Pareto.

Assessing the Figure \ref{fig:paretoEP1}, we can observe beforehand the reference pareto front. It's possible to notice its great extension, going from values near 100\% to values near 50\%, always showing the best values of thermal cost. This great distribution of values is because it's made of the combination of the best solutions of all the executions of all the algorithms.

%Focando nos algoritmos de enxames de partículas, podemos notar que, assim como apontado pelo Indicador \textit{I}$^{1}_{\epsilon+}$, o OMOPSO realmente obteve resultados melhores, visto que seus pontos estão mais próximos da Frente de Pareto. Entretanto, assim como foi visto no Indicador $\Delta$, o SMPSO realmente obteve uma distribuição muito maior do que o OMOPSO, dando muito mais opções de soluções, o que poderia permitir maior ajuste fino por parte do operador do sistema.

Focusing in the particle swarm optimization algorithms, it's noticeable, as pointed out by the \textit{I}$^{1}_{\epsilon+}$ Indicator, that the OMPSO really achieved better results, since its solutions are closer to the reference pareto front. However, as indicated by the $\Delta$ Indicator, the SMPSO really obtained a much larger distribution than the OMOPSO, presenting a lot more options, what could allow for the system's operator to make some fine adjustments.

%Ao analisarmos os algoritmos evolucionários, notamos que, apesar de apresentar melhores resultados de acordo com o Indicador \textit{I}$^{1}_{\epsilon+}$, o MOCell tem boa parte de suas soluções dominadas pelas soluções do NSGA-II e o SPEA2. Entretanto, devemos nos lembrar que o \textit{I}$^{1}_{\epsilon+}$ é calculado utilizando a distância de cada ponto da Frente de Pareto, para indicar assim o quanto um conjunto de soluções se aproxima dela. Isso justifica o bom valor do MOCell, visto que sua extensão de soluções cobre até mesmo valores de armazenamento inferiores a 50\%, possuindo sempre soluções próximas às da Frente de Pareto. Enquanto isso, as soluções encontradas pelo NSGA-II chegam no máximo a valores de armazenamento superiores a 70\% e o SPEA2 a valores superiores a 60\%. O que significa que o MOCell daria um leque de opções muito maior do que seus rivais, de forma que o operador do sistema, em casos críticos, poderia escolher sacrificar um pouco mais do volume final em prol de menor custo térmico. Algo que não seria possível com os demais algoritmos.

Analysing the evolutionary algorithms, we can see that even though the MOCell presented the best results according to \textit{I}$^{1}_{\epsilon+}$ Indicator, a good amount of its solutions are dominated by NSGA-II and SPEA2's solutions. But it's worth mentioning that \textit{I}$^{1}_{\epsilon+}$ is calculated using the distance of each point of the reference pareto front, indicating how closer is another pareto front is to it. This justifies the good result of MOCell, given that its extension of solutions covers even storage values smaller than 50\%, having solutions nearby every point of the reference pareto front. Meanwhile, the solutions found by NSGA-II and SPEA2 cover a much smaller extension, achieving storage values larger than 70\% and 60\%, respectively. It means that the MOCell can give many more options for the system operators than its rivals can, in a way that the operator could choose, in some critical cases, sacrifice some final storage to achieve less thermal cost.

%Além disso, o MOCell também deu maiores opções com maior volume final do que seus concorrentes. Conclui-se, então, que ele seria a melhor opção de acordo com o aspecto de distribuição de valores. Entretanto, o NSGA-II e o SPEA2, como já apontado, possuem soluções melhores em quase toda a área de cobertura dos mesmos. As frentes de pareto de ambos se cruzam bastante, havendo pontos em que um é superior ao outro, mas o desempate fica a favor do NSGA-II, como pudemos ver através de todos os indicadores.

We can conclude that the MOCell would be the best option according to the diversity aspect. However, NSGA-II and SPEA2, as pointed out, achieved better results in almost their whole extension. Their pareto fronts cross quite some times, having points where one of them is better than the other and also the other way. But NSGA-II is better, as indicated by the indicators.

\begin{figure}[!t]
  \centering
  \caption{Pareto Fronts of the Means \textit{I}$^{1}_{\epsilon+}$ Indicator of the first period}
  \resizebox{\columnwidth}{!}{\input{./fig/Frente-de-Pareto_EP_1_en.pdf_tex}}
  \label{fig:paretoEP1}
\end{figure}

%\subsection{Perí­odo 1961-1966}
\subsection{1961-1966}

%Este é um período de vazões medianas. Portanto, espera-se melhores resultados de todos os algoritmos. Poderemos assim, avaliar o comportamento dos mesmo em uma situação de menor dificuldade do que a apresentada anteriormente.

This is the period of medium affluences. Therefore, better results are expected to be achieved by all the algorithms. This way, it's possible to evaluate them in a situation of less difficult than the previously presented.

%Como pode ser visto na Tabela \ref{table:epPeriodo2}, os resultados do período anterior se mantiveram ao analisarmos o Indicador \textit{I}$^{1}_{\epsilon+}$. Em relação ao índice de distribuição, o valor de $1.0$ continua sendo o melhor em todos os algoritmos. Entretanto, deve-se notar que a diferença dos resultados teve uma considerável acentuada, sendo que aqueles com valor $1.0$ acabaram obtendo resultados expressivamente melhores do que os demais.

As shown in the Table \ref{table:epPeriodo2}, the results are consistent with the ones of the previous period when analysing the \textit{I}$^{1}_{\epsilon+}$ Indicator. Regarding the distribution index, the value of $1.0$ is still the best for all the algorithms. However, it's worth noting that the difference between the results is much larger now, being that the ones with the value $1.0$ are substantially better than the others.

%Comparando os algoritmos de enxame de partículas, observamos o mesmo do que no período passado. Novamente, o vencedor foi o OMOPSO de acordo com o Indicador \textit{I}$^{1}_{\epsilon+}$. Da mesma forma, se mantiveram os resultados dos algoritmos evolucionários, em que o MOCell se manteve à frente, seguido pelo NSGA-II e o SPEA2.

Comparing the particle swarm optimization algorithms, the same outcome of the previous period is found. Again, the winner was the OMOPSO according to \textit{I}$^{1}_{\epsilon+}$ Indicator. The same way, the order of the evolutionary algorithms didn't change.

\begin{table}[!t]
\caption{Mean and Standard Deviation of Additive Epsilon Indicator (\textit{I}$^{1}_{\epsilon+}$) of the second period.}
\label{table:epPeriodo2}
\centering
\begin{tabular}{ll}
    \hline
    ~              & Mean and Standard Deviation               \\ \hline
    OMOPSO         & $  1.93e+00_{ 5.8e-01}$                   \\
    SMPSO (1.0)    & $  2.73e+00_{ 4.0e-01}$                   \\
    SMPSO (10.0)   & $  3.13e+00_{ 7.1e-01}$                   \\
    SMPSO (20.0)   & $  3.09e+00_{ 8.7e-01}$                   \\
    NSGA-II (1.0)  & \cellcolor{gray25}$  5.13e-01_{ 2.5e-01}$ \\
    NSGA-II (10.0) & $  8.82e-01_{ 2.1e-01}$                   \\
    NSGA-II (20.0) & $  1.38e+00_{ 3.1e-01}$                   \\
    SPEA2 (1.0)    & $  6.30e-01_{ 2.5e-01}$                   \\
    SPEA2 (10.0)   & $  8.54e-01_{ 3.0e-01}$                   \\
    SPEA2 (20.0)   & $  1.20e+00_{ 4.2e-01}$                   \\
    MOCell (1.0)   & \cellcolor{gray95}$  3.19e-01_{ 1.4e-01}$ \\
    MOCell (10.0)  & $  1.15e+00_{ 2.7e-01}$                   \\
    MOCell (20.0)  & $  1.92e+00_{ 6.1e-01}$                   \\
    \end{tabular}
\end{table}

%Os resultados começam a se diferenciar do período anterior ao anarlisarmos o Indicador $\Delta$. Como pode ser visto na Tabela \ref{table:spreadPeriodo2}, os resultados dos algoritmos foram bem próximos nessa métrica. Entretanto, diferente do período anterior, quem se destacou foi o MOCell e o OMOPSO. Vale lembrar que os dois melhores do período anterior foram o SMPSO e o OMOPSO, respectivamente. Isso demonstra que nesse problema de dificuldade mediana, o SMPSO acabou perdendo no aspecto de distribuição, que foi seu melhor atributo no primeiro período.

The difference of the results starts to show up when analysing the $\Delta$ Indicator. As presented in the Table \ref{table:spreadPeriodo2}, the results of the algorithms were very close in this metric. Also, unlike the previous period, the best algorithms according to this indicator was MOCell and OMOPSO. To remid, the best two were SMPSO and OMOPSO, respectively. This shows that in this medium difficulty problem, the SMPSO ended up losing in its best previous attribute: diversity.

\begin{table}[!t]
\caption{Mean and Standard Deviation of the SPREAD Indicator ($\Delta$) of the second period}
\label{table:spreadPeriodo2}
\centering
\begin{tabular}{ll}
    \hline
    ~              & Mean and Standard Deviation                   \\ \hline
    OMOPSO         & \cellcolor{gray25}$  8.21e-01_{ 7.1e-02}$ \\
    SMPSO (1.0)    & $  9.01e-01_{ 4.7e-02}$                   \\
    SMPSO (10.0)   & $  8.98e-01_{ 3.2e-02}$                   \\
    SMPSO (20.0)   & $  8.87e-01_{ 4.5e-02}$                   \\
    NSGA-II (1.0)  & $  9.63e-01_{ 5.1e-02}$                   \\
    NSGA-II (10.0) & $  9.26e-01_{ 3.8e-02}$                   \\
    NSGA-II (20.0) & $  9.59e-01_{ 1.9e-02}$                   \\
    SPEA2 (1.0)    & $  9.76e-01_{ 6.2e-02}$                   \\
    SPEA2 (10.0)   & $  9.17e-01_{ 4.6e-02}$                   \\
    SPEA2 (20.0)   & $  9.29e-01_{ 3.3e-02}$                   \\
    MOCell (1.0)   & \cellcolor{gray95}$  7.70e-01_{ 6.8e-02}$ \\
    MOCell (10.0)  & $  8.77e-01_{ 3.2e-02}$                   \\
    MOCell (20.0)  & $  9.52e-01_{ 2.9e-02}$                   \\
    \end{tabular}
\end{table}

%Para finalizar, a Tabela \ref{table:hvPeriodo2} mostra os resultados desse período de acordo com o Indicador HV. Os resultados que apresentam o símbolo '-' indicam aqueles experimentos cujo valor de HV é 0, o que significa que o conjunto de soluções obtido está fora dos limites da Frente de Pareto de referência. Assim, dá-se o valor de 0 porque, caso contrário, os resultados obtidos não seriam confiáveis. Então, não será possível fazer a mesma análise feita no período anterior, visto que não obtivemos o valor de HV para todos algoritmos. Entretanto, com os resultados disponíveis, notamos uma diferença em relação ao período anterior, visto que dessa vez o MOCell superou o NSGA-II e o SPEA2 também nesse indicador. Mas antes das conclusões desse período, veremos os gráficos.

To proceed, the Table \ref{table:hvPeriodo2} show the results of this period according to the HV Indicator. The lines presenting the '-' symbol indicate the results which HV's value is $0$, which means that the set of obtained solutions were out of the range of the reference pareto front. When solutions are out of range, the value of the HV can't be trusted because of how it's calculated. That's why its value is assumed to be $0$. So, it's not possible to do the same analysis of the previous period, given we don't have HV values for all the algorithms. Anyway, with the available results, it's possible to notice a difference to the previous period, given that this time the MOCell surpassed both NSGA-II and SPEA2 according to this indicator.

\begin{table}[!t]
\caption{Mean and Standard Deviation of the Hypervolume Indicator (HV) of the second period}
\label{table:hvPeriodo2}
\centering
\begin{tabular}{ll}
    \hline
    ~              & Mean and Standard Deviation               \\ \hline
    OMOPSO         & -                                         \\
    SMPSO (1.0)    & -                                         \\
    SMPSO (10.0)   & -                                         \\
    SMPSO (20.0)   & -                                         \\
    NSGA-II (1.0)  & \cellcolor{gray25}$  2.93e-01_{ 1.8e-01}$ \\
    NSGA-II (10.0) & $  1.02e-01_{ 1.9e-01}$                   \\
    NSGA-II (20.0) & -                                         \\
    SPEA2 (1.0)    & $  2.00e-01_{ 1.5e-01}$                   \\
    SPEA2 (10.0)   & $  1.04e-01_{ 1.9e-01}$                   \\
    SPEA2 (20.0)   & -                                         \\
    MOCell (1.0)   & \cellcolor{gray95}$  3.02e-01_{ 1.7e-01}$ \\
    MOCell (10.0)  & -                                         \\
    MOCell (20.0)  & -                                         \\
    \end{tabular}
\end{table}

%Para concluir a análise desse período de dificuldade mediana, podemos verificar a Figura \ref{fig:paretoEP2}. Assim como feito no período anterior, foram utilizadas as medianas de cada algoritmo, incluindo apenas seu melhor valor do índice de distribuição.



\begin{figure}[!t]
  \centering
  \caption{Pareto Fronts of the Means \textit{I}$^{1}_{\epsilon+}$ Indicator of the second period}
  \resizebox{\columnwidth}{!}{\input{./fig/Frente-de-Pareto_EP_2_en.pdf_tex}}
  \label{fig:paretoEP2}
\end{figure}

%A primeira análise que podemos observar nessas figuras é que elas deixam claro a maior facilidade em na otimização para esse segundo período. A própria Frente de Pareto de referência obteve valores maiores de 82\% de volume final, enquanto otimizava o custo térmico. Inclusive, muitos resultados se encontraram muito próximos de 100\% de armazenamento.

To conclude the analysis of this period of medium difficulty, there's the Figure \ref{fig:paretoEP2}, following the same patten of the Figure \ref{fig:paretoEP2}, as explained previously. The first thing to observe is that the solutions found by the algorithms are way better than the first period, as expected. The reference pareto front, for example, presented all solutions with final storage higher than 82\%. Also, most of the solutions were very close to having 100\% of the final volume of the reservoirs.

%Quanto aos algoritmos de Enxame de Partículas, novamente o SMPSO um conjunto grande de soluções em sua Frente de Pareto. Entretanto, mesmo com um número baixo de soluções, o OMOPSO conseguiu, em alguns casos, maior distribuição de seus valores. E além disso, todas suas soluções dominavam as do SMPSO. Comprovando mais uma vez que o OMOPSO supera seu antecessor nesse problema de otimização de hidrelétricas.

Bringing our attention to the particle swarm optimization algorithms, once again the SMPSO presented a large set of solutions in its pareto front. However, even with a small number of solutions, the OMOPSO achieved, in some cases, a greater diversity of solutions. Beyond that, all of its solutions dominated the SMPSO ones. Proving one more time that OMOPSO is better than it successor in optimizing the operation of hydroelectric plants.

%Os algoritmos evolucionários tiveram resultados similares. Novamente, as soluções do NSGA-II domina do SPEA2 e ambas dominam do MOCell. Entretanto, a distribuição de soluções do MOCell é muito maior. Isso significa que, num caso de grande necessidade de redução de custos, o operador do sistema poderia escolher sacrificar mais do volume final, o que não poderia ser feito nos demais algoritmos.

The evolutionary algorithms achieved similar results. Once more, the solutions of NSGA-II dominated the solutions of SPEA2 and both of theirs dominated the ones of MOCell. However, the diversity of solutions of MOCell is far superior. It means that, in case of a great need to reduce the costs, the system's operator would be able to choose to sacrifice more of the final storage when using MOCell.

%\subsection{Perí­odo 1980-1985}
\subsection{1980-1985}

%Por último, analisaremos o período de tempo mais fácil de ser resolvido, devido à abundância de água gerada pelas cheias. Portanto, espera-se novamente que os resultados apresentem altos valores de volume final com valores mais baixos de custo térmico.

Lastly, we'll analyse the easiest period, thanks to the abundance of water because of the rains. So, it's expected that the algorithms will find even better results than previously.

%A partir da Tabela \ref{table:epPeriodo3}, podemos ver os resultados dos algoritmos de acordo com o Indicador \textit{I}$^{1}_{\epsilon+}$. Novamente, nota-se que os algoritmos de Enxame de Partículas ficaram muito atrás se comparados com os evolucionários. Além disso, os resultados se mantiveram parecidos com o que foi visto nos períodos anteriores. O melhor resultado para esse indicador foi novamente o MOCell, seguido do NSGA-II. Novamente, os índices de distribuição mais baixo obtiveram valores melhores.

Starting with the Table \ref{table:epPeriodo3}, we can visualize the results of the algorithms according to the \textit{I}$^{1}_{\epsilon+}$ Indicator. Once more, It's noticeable that the particle swarm algorithms was behind when compared to the evolutionary algorithms. Beyond that, the results look similar to what was seen in the previous periods. The best result for this indicator was again the MOCell, followed by NSGA-II. Also, one more time the smaller distribution indexes worked better.

\begin{table}[!t]
\caption{Mean and Standard Deviation of Additive Epsilon Indicator (\textit{I}$^{1}_{\epsilon+}$) of the third period}
\label{table:epPeriodo3}
\centering
\begin{tabular}{ll}
    \hline
    ~              & Mean and Standard Deviation               \\ \hline
    OMOPSO         & $  4.06e+00_{ 8.8e-01}$                   \\
    SMPSO (1.0)    & $  6.56e+00_{ 1.5e+00}$                   \\
    SMPSO (10.0)   & $  6.96e+00_{ 1.7e+00}$                   \\
    SMPSO (20.0)   & $  7.96e+00_{ 1.6e+00}$                   \\
    NSGA-II (1.0)  & \cellcolor{gray25}$  5.87e-01_{ 2.7e-01}$ \\
    NSGA-II (10.0) & $  1.54e+00_{ 5.5e-01}$                   \\
    NSGA-II (20.0) & $  2.61e+00_{ 8.3e-01}$                   \\
    SPEA2 (1.0)    & $  1.11e+00_{ 5.8e-01}$                   \\
    SPEA2 (10.0)   & $  1.66e+00_{ 3.6e-01}$                   \\
    SPEA2 (20.0)   & $  3.18e+00_{ 7.8e-01}$                   \\
    MOCell (1.0)   & \cellcolor{gray95}$  5.06e-01_{ 4.4e-01}$ \\
    MOCell (10.0)  & $  1.71e+00_{ 4.4e-01}$                   \\
    MOCell (20.0)  & $  3.27e+00_{ 1.0e+00}$                   \\
    \end{tabular}
\end{table}

%Uma diferença que podemos notar é que a diferença dos dois melhores algoritmos para os demais cresceu bastante nesse período. Enquanto os resultados do MOCell e do NSGA-II foram da ordem de $10^{-1}$, os demais tiveram resultados da ordem de $10^{0}$. Isso reforça mais a superioridade de ambos algoritmos para esse problema de otimização.

One difference to be noted is that the gap between the best two algorithms and the others increased substantially in this period. While the results of MOCell and NSGA-II were of the order of $10^{-1}$, the others obtained results of the order of $10^{0}$. This reinforces the superiority of both algorithms to solve this optimization problem.

%Em relação à distribuição, que pode ser analisada através da Tabela \ref{table:spreadPeriodo3}, que mostra os resultados do Indicador $\Delta$, o MOCell continua bem à frente dos demais. Os outros algoritmos estão razoavelmente próximos nesse quesito. Também vale notar que o OMOPSO venceu seu sucessor SMPSO também nesse aspecto, nesse período.

Regarding the diversity aspect, which can be analysed through the Table \ref{table:spreadPeriodo3} with the results of the $\Delta$ Indicator, the MOCell is still far ahead of the others, that are reasonable close on this aspect. It's also worth noting that the OMOPSO was better than SMPSO again.

\begin{table}[!t]
\caption{Mean and Standard Deviation of the SPREAD Indicator ($\Delta$) of the third period}
\label{table:spreadPeriodo3}
\centering
\begin{tabular}{ll}
    \hline
    ~              & Mean and Standard Deviation               \\ \hline
    OMOPSO         & $  9.22e-01_{ 4.3e-02}$                   \\
    SMPSO (1.0)    & $  9.40e-01_{ 3.2e-02}$                   \\
    SMPSO (10.0)   & $  9.32e-01_{ 2.3e-02}$                   \\
    SMPSO (20.0)   & $  9.47e-01_{ 2.7e-02}$                   \\
    NSGA-II (1.0)  & \cellcolor{gray25}$  9.16e-01_{ 6.1e-02}$ \\
    NSGA-II (10.0) & $  9.54e-01_{ 2.3e-02}$                   \\
    NSGA-II (20.0) & $  9.80e-01_{ 1.4e-02}$                   \\
    SPEA2 (1.0)    & $  9.56e-01_{ 5.1e-02}$                   \\
    SPEA2 (10.0)   & $  9.38e-01_{ 3.0e-02}$                   \\
    SPEA2 (20.0)   & $  9.70e-01_{ 2.0e-02}$                   \\
    MOCell (1.0)   & \cellcolor{gray95}$  7.95e-01_{ 7.5e-02}$ \\
    MOCell (10.0)  & $  9.22e-01_{ 2.5e-02}$                   \\
    MOCell (20.0)  & $  9.85e-01_{ 9.5e-03}$                   \\
    \end{tabular}
\end{table}

%Por fim, temos o último Indicador: Hipervolume. A Tabela \ref{table:hvPeriodo3} mostra os resultados dele. E como podemos ver, apenas dois algoritmos tiveram valor atribuído. O que significa que todos os outros tiveram sua extensão maiores do que a Frente de Pareto de referência. Porém, essa falta de valores, essa tabela reforça o fato do NSGA-II obter resultados que dominam os do MOCell. Diferente do segundo período, isso foi bem demonstrado tanto no primeiro quanto no terceiro período através do HV.

Lastly, there's the last Indicator for this period: Hypervolume. The Table \ref{table:hvPeriodo3} presents its results. As we can see, only two algorithms had their values set. It means that all of the others were out of range of the reference pareto front. Anyway, this Table reinforces that fact that the NSGA-II achieves solutions that dominates the ones of the MOCell.

\begin{table}[!t]
\caption{Mean and Standard Deviation of the Hypervolume Indicator (HV) of the third period}
\label{table:hvPeriodo3}
\centering
\begin{tabular}{ll}
    \hline
    ~              & Mean and Standard Deviation               \\ \hline
    OMOPSO         & -                                         \\
    SMPSO (1.0)    & -                                         \\
    SMPSO (10.0)   & -                                         \\
    SMPSO (20.0)   & -                                         \\
    NSGA-II (1.0)  & \cellcolor{gray95}$  2.62e-01_{ 2.0e-01}$ \\
    NSGA-II (10.0) & -                                         \\
    NSGA-II (20.0) & -                                         \\
    SPEA2 (1.0)    & -                                         \\
    SPEA2 (10.0)   & -                                         \\
    SPEA2 (20.0)   & -                                         \\
    MOCell (1.0)   & \cellcolor{gray25}$  1.69e-01_{ 2.0e-01}$ \\
    MOCell (10.0)  & -                                         \\
    MOCell (20.0)  & -                                         \\
    \end{tabular}
\end{table}

%Para concluir a análise dos resultados desse período, podemos observar a Figura \ref{fig:paretoEP3}. A primeira coisa que podemos notar é que os valores finais de armazenamento ficaram ainda maiores. Observando a Frente de Pareto de referência, notamos que o menor valor encontrado está por volta de 85\%. Os valores de custo térmico caíram drasticamente também em relação aos períodos anteriores. Isso mostra o que já era esperado: os algoritmos conseguem resultados muito melhores em um período de cheias devido à facilidade do problema.

To conclude the analysis of this period, we can observe the Figure \ref{fig:paretoEP3}. The first thing to be noticed is that the final volume of the reservoirs is even greater. The reference pareto front, for example, presents values of final storage higher than 85\%. The thermal costs has fallen down drastically as well in relation to the previous periods. This confirms what was expected: the algorithms can obtain better results in a period of abundance of water.

%Focando primeiramente nos algoritmos de Enxame de Partículas, vemos que o OMOPSO realmente obteve resultados melhores que o SMPSO, mas ainda com um conjunto de soluções muito menor. Também, ambos ficaram bem atrás dos algoritmos evolucionários.

Focusing first on the particle swarm optimization algorithms, the figure shows that the OMOPSO is really better than SMPSO for this problem, even though it presents a smaller quantity of solutions. Also, both are far behind the evolutionary algorithms.

%Esses se aproximaram bem da Frente de Pareto. Mas, novamente, os melhores resultados foram do NSGA-II. Apesar que esse sempre apresenta uma distribuição bem menor do que o MOCell. O SPEA2 teve também bons resultados, mas esteve novamente atrás do NSGA-II e também não vence superior distribuição do MOCell.

On the other hand, the the evolutionary algorithms got really close to the reference pareto front. But, again, the best results were from NSGA-II. Even thoug it presents a much lower diversity than MOCell. SPEA2 also exhibits good results, but its still behind NSGA-II and doesn't have a great diversity that MOCell has.

\begin{figure}[!t]
  \centering
  \caption{Pareto Fronts of the Means \textit{I}$^{1}_{\epsilon+}$ Indicator of the third period}
  \resizebox{\columnwidth}{!}{\input{./fig/Frente-de-Pareto_EP_3_en.pdf_tex}}
  \label{fig:paretoEP3}
\end{figure}

%\subsection{Resultados Finais}
\subsection{Final Results}

%Por fim, podemos tratar dos resultados finais dos algoritmos apresentados e testados para o problema de otimização da operação de usinas hidrelétricas. Primeiramente, observamos que os algoritmos evolucionários se adaptaram muito melhor ao problema do que os de Enxame de Partículas, obtendo resultados melhores em todos os casos. Dentre os de Enxame de Partículas, o OMOPSO foi melhor do que o SMPSO, apesar da baixa quantidade de pontos em sua Frente de Pareto. Enquanto isso, o melhor algoritmo, sem dúvidas, foi o NSGA-II. Ele obteve os resultados mais próximos da Frente de Pareto de referência, sempre superior aos demais. O segundo melhor, apesar de ter suas soluções em parte dominadas pelo do SPEA2, foi o MOCell. Sua grande vantagem apresentada foi sua grande distribuição de soluções, o que permite alguns ajustes finos e uma maior gama de escolha ao operador do sistema.

To conclude our study cases, we can consider the final results of the evaluated algorithms. First, we noticed that the evolutionary algorithms has adapted far better than the particle swarm optimization algorithms to this problem, obtaining better results in every case. Among the particle swarm algorithms, the OMOPSO was the best, despite its low amount of solutions in its pareto front. Meanwhile, the best algorithm, with no doubt, was the NSGA-II. This one achieved the closest results to the reference pareto front. The second best, even though it had a good amount of its solutions dominated by SPEA2, was MOCell. Its great advantage was its great diversity of solutions, which would allow the operator to do fine adjustments with its larger range of solutions.

%Portanto, se fossemos recomendar algoritmos para a solução desse problema, os dois recomendados seriam NSGA-II e MOCell. Combinando as soluções de ambos, podemos conseguir uma boa Frente de Pareto com boas soluções e ainda com uma boa distribuição.

Therefore, we would recomend both NSGA-II and MOCell to optimize this problem. If their solutions are combined, it's possible to generate a good pareto front with excellent solutions and also a good diversity.